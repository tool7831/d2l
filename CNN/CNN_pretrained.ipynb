{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ub_hNd3GNPYp"},"outputs":[],"source":["!pip install einops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lh9VEIvBXNh3"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('content/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGrH748qIbt7"},"outputs":[],"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from torch import optim\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import os\n","import json\n","from torchvision import utils\n","\n","\n","from torch import nn\n","from torch import Tensor\n","from PIL import Image\n","from torchvision.transforms import Compose, Resize, ToTensor\n","from einops import rearrange, reduce, repeat\n","from einops.layers.torch import Rearrange, Reduce\n","from torchsummary import summary\n","import numpy as np\n","import pandas as pd\n","import time\n","import copy\n","import random\n","from tqdm.notebook import tqdm\n","import math\n","\n","# Device configuration\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"GPU가 사용 가능합니다.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU를 사용할 수 없습니다.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wKk6NatXMVP"},"outputs":[],"source":["trainpath = '/content/content/MyDrive/etc/aihub-meat-image/Training/'\n","valpath = '/content/content/MyDrive/etc/aihub-meat-image/Validation/'\n","train_imagepath = os.path.join(trainpath, '[image]cow_seg_')\n","val_imagepath = os.path.join(valpath,'[image]cow_seg_')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IRp8EGnTXUw5"},"outputs":[],"source":["# JSON 파일이 있는 디렉토리 경로\n","train_labelpath = []\n","train_labelpath.append(os.path.join(trainpath, '[label]cow_seg_1'))\n","train_labelpath.append(os.path.join(trainpath, '[label]cow_seg_2'))\n","train_labelpath.append(os.path.join(trainpath, '[label]cow_seg_3'))\n","\n","val_labelpath = []\n","val_labelpath.append(os.path.join(valpath, '[label]cow_seg_1'))\n","val_labelpath.append(os.path.join(valpath, '[label]cow_seg_2'))\n","val_labelpath.append(os.path.join(valpath, '[label]cow_seg_3'))\n","\n","# 라벨 정보를 저장할 딕셔너리\n","jsons = []\n","\n","# JSON 디렉토리 내의 모든 파일에 대해 라벨 정보 추출\n","for path in train_labelpath:\n","  for filename in os.listdir(path):\n","    if filename.endswith(\".json\"):\n","      json_path = os.path.join(path, filename)\n","\n","      # JSON 파일 로드\n","      with open(json_path) as f:\n","        json_data = json.load(f)\n","\n","      # 라벨 정보 추출\n","      jsons.append(json_data)\n","\n","train_labels = []\n","for d in jsons:\n","  label = [d[\"label_info\"][\"image\"][\"file_name\"],\n","           d[\"label_info\"][\"shapes\"][0][\"label\"],\n","           d[\"label_info\"][\"shapes\"][0][\"grade\"],\n","           d[\"label_info\"][\"shapes\"][0][\"gender\"],\n","          ]\n","  train_labels.append(label)\n","\n","# 라벨 정보를 저장할 딕셔너리\n","jsons = []\n","\n","# JSON 디렉토리 내의 모든 파일에 대해 라벨 정보 추출\n","for path in val_labelpath:\n","  for filename in os.listdir(path):\n","    if filename.endswith(\".json\"):\n","      json_path = os.path.join(path, filename)\n","\n","      # JSON 파일 로드\n","      with open(json_path) as f:\n","        json_data = json.load(f)\n","\n","      # 라벨 정보 추출\n","      jsons.append(json_data)\n","\n","val_labels = []\n","for d in jsons:\n","  label = [d[\"label_info\"][\"image\"][\"file_name\"],\n","           d[\"label_info\"][\"shapes\"][0][\"label\"],\n","           d[\"label_info\"][\"shapes\"][0][\"grade\"],\n","           d[\"label_info\"][\"shapes\"][0][\"gender\"],\n","          ]\n","  val_labels.append(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2U0bYOS7XWsC"},"outputs":[],"source":["train_label_set = pd.DataFrame(data=train_labels, columns=['file_name','label','grade','gender'])\n","val_label_set = pd.DataFrame(data=val_labels, columns=['file_name','label','grade','gender'])\n","print(train_label_set)\n","print(val_label_set)\n","\n","def grade_encoding(x):\n","  if x == '1':\n","    return 0\n","  elif x == '2':\n","    return 1\n","  elif x== '3':\n","    return 2\n","  return 0\n","\n","one_hot_labels = torch.eye(3)[[0,1,2]]\n","\n","print(one_hot_labels)\n","\n","train_label_set['grade_encode'] = train_label_set['grade'].apply(grade_encoding)\n","val_label_set['grade_encode'] = val_label_set['grade'].apply(grade_encoding)\n","\n","print(train_label_set)\n","print(val_label_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5g7bG90pXYsg"},"outputs":[],"source":["\n","class CustomImageDataset(Dataset):\n","  def __init__(self, labels, img_dir, transform=None, target_transform=None):\n","    self.img_dir = img_dir\n","    self.transform = transform\n","    self.target_transform = target_transform\n","    self.img_labels = labels\n","    #self.train = train\n","    #self.train_len = int(len(labels) * 0.8)\n","    #if train == True:\n","    #  self.img_labels = labels[:self.train_len]\n","    #else:\n","    #  self.img_labels = labels[self.train_len:]\n","\n","  def __len__(self):\n","    return len(self.img_labels)\n","\n","  def __getitem__(self, idx):\n","    img_path = self.img_dir + str(self.img_labels.iloc[idx]['grade'])\n","    img_path = os.path.join(img_path, self.img_labels.iloc[idx, 0])\n","    image = Image.open(img_path)\n","    label = self.img_labels.iloc[idx]['grade_encode']\n","    if self.transform:\n","        image = self.transform(image)\n","    if self.target_transform:\n","        label = self.target_transform(label)\n","    return image, label\n","\n","transformation = transforms.Compose([\n","    transforms.Resize([224,224]),\n","    transforms.ToTensor(),\n","    ])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d5zNi5hHXdKc"},"outputs":[],"source":["train_set = CustomImageDataset(train_label_set, train_imagepath, transform=transformation)\n","val_set = CustomImageDataset(val_label_set, val_imagepath, transform=transformation)\n","\n","train_dl = DataLoader(train_set, batch_size=16, shuffle=True,num_workers=4)\n","val_dl = DataLoader(val_set,batch_size=8, shuffle = True, num_workers=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OJxcv0yyJ2VC"},"outputs":[],"source":["weights = torchvision.models.ResNet101_Weights.DEFAULT\n","model = torchvision.models.resnet101(weights=weights)\n","model.fc = nn.Linear(in_features=2048, out_features=3)\n","transformation = weights.transforms()\n","model.to(device)\n","print(transformation)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZYB1lq-aNFJw"},"outputs":[],"source":["summary(model,(3,224,224))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"804c7QwNNl14"},"outputs":[],"source":["loss_func = nn.CrossEntropyLoss(reduction='sum')\n","opt = optim.Adam(model.parameters(), lr=0.01)\n","\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EwKG1KokOF6h"},"outputs":[],"source":["# get current lr\n","def get_lr(opt):\n","    for param_group in opt.param_groups:\n","        return param_group['lr']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8KKm6s3JX0FV"},"outputs":[],"source":["# calculate the metric per mini-batch\n","def metric_batch(output, target):\n","    pred = output.argmax(1, keepdim=True)\n","    corrects = pred.eq(target.view_as(pred)).sum().item()\n","    return corrects\n","\n","# calculate the loss per mini-batch\n","def loss_batch(loss_func, output, target, opt=None):\n","    loss_b = loss_func(output, target)\n","    metric_b = metric_batch(output, target)\n","\n","    if opt is not None:\n","        opt.zero_grad()\n","        loss_b.backward()\n","        opt.step()\n","\n","    return loss_b.item(), metric_b\n","\n","# calculate the loss per epochs\n","def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n","    running_loss = 0.0\n","    running_metric = 0.0\n","    len_data = len(dataset_dl.dataset)\n","\n","    for xb, yb in dataset_dl:\n","        xb = xb.to(device)\n","        yb = yb.to(device)\n","        output = model(xb)\n","        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n","\n","        running_loss += loss_b\n","\n","        if metric_b is not None:\n","            running_metric += metric_b\n","\n","        if sanity_check is True:\n","            break\n","\n","    loss = running_loss / len_data\n","    metric = running_metric / len_data\n","    return loss, metric"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1WOGGtAFOAWk"},"outputs":[],"source":["# function to start training\n","def train_val(model, params):\n","    num_epochs=params['num_epochs']\n","    loss_func=params['loss_func']\n","    opt=params['optimizer']\n","    train_dl=params['train_dl']\n","    val_dl=params['val_dl']\n","    sanity_check=params['sanity_check']\n","    lr_scheduler=params['lr_scheduler']\n","    path2weights=params['path2weights']\n","\n","    loss_history = {'train': [], 'val': []}\n","    metric_history = {'train': [], 'val': []}\n","\n","    best_loss = float('inf')\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    start_time = time.time()\n","\n","    for epoch in range(num_epochs):\n","        current_lr = get_lr(opt)\n","        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n","\n","        model.train()\n","        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n","        loss_history['train'].append(train_loss)\n","        metric_history['train'].append(train_metric)\n","\n","        model.eval()\n","        with torch.no_grad():\n","            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n","        loss_history['val'].append(val_loss)\n","        metric_history['val'].append(val_metric)\n","\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            torch.save(model.state_dict(), path2weights)\n","            print('Copied best model weights!')\n","\n","        lr_scheduler.step(val_loss)\n","        if current_lr != get_lr(opt):\n","            print('Loading best model weights!')\n","            model.load_state_dict(best_model_wts)\n","\n","        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n","        print('-'*10)\n","\n","    model.load_state_dict(best_model_wts)\n","    return model, loss_history, metric_history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NVfAgUGvOOzd"},"outputs":[],"source":["# define the training parameters\n","params_train = {\n","    'num_epochs':20,\n","    'optimizer':opt,\n","    'loss_func':loss_func,\n","    'train_dl':train_dl,\n","    'val_dl':val_dl,\n","    'sanity_check':False,\n","    'lr_scheduler':lr_scheduler,\n","    'path2weights':'./models/weights.pt',\n","}\n","\n","# check the directory to save weights.pt\n","def createFolder(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSError:\n","        print('Error')\n","createFolder('./models')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAQQrqJ_OQVa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c23ff7d1-25c9-4a46-f803-90cb8539e144"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 0/19, current lr= 0.01\n"]}],"source":["model, loss_hist, metric_hist = train_val(model, params_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Z--HBo3OSsB"},"outputs":[],"source":["num_epochs = params_train['num_epochs']\n","\n","# Plot train-val loss\n","plt.title('Train-Val Loss')\n","plt.plot(range(1, num_epochs+1), loss_hist['train'], label='train')\n","plt.plot(range(1, num_epochs+1), loss_hist['val'], label='val')\n","plt.ylabel('Loss')\n","plt.xlabel('Training Epochs')\n","plt.legend()\n","plt.show()\n","\n","# plot train-val accuracy\n","plt.title('Train-Val Accuracy')\n","plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')\n","plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Training Epochs')\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiFprcSEyvcBmJJpj6GhKd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}