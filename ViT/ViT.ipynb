{"cells":[{"cell_type":"markdown","metadata":{"id":"hzz7xBr5FPZ5"},"source":["# Reference\n","* https://deep-learning-study.tistory.com/807\n","* https://towardsdatascience.com/implementing-visualttransformer-in-pytorch-184f9f16f632"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6131,"status":"ok","timestamp":1687150532471,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"oSyhQWdXbe84","outputId":"73786a4c-8cde-4eeb-e18b-7957300210b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"]}],"source":["!pip install einops"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2429,"status":"ok","timestamp":1687150534896,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"uFlOqgD6XQQ_","outputId":"430b569e-cf39-46b9-99ea-f9182fd54a85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at content/; to attempt to forcibly remount, call drive.mount(\"content/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('content/')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2065,"status":"ok","timestamp":1687150536959,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"aP77CCTiR4hU","outputId":"152869f5-c153-4d13-b543-7a47379dcb7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU가 사용 가능합니다.\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from torch import optim\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import os\n","import json\n","from torchvision import utils\n","\n","\n","from torch import nn\n","from torch import Tensor\n","from PIL import Image\n","from torchvision.transforms import Compose, Resize, ToTensor\n","from einops import rearrange, reduce, repeat\n","from einops.layers.torch import Rearrange, Reduce\n","from torchsummary import summary\n","import numpy as np\n","import pandas as pd\n","import time\n","import copy\n","import random\n","from tqdm.notebook import tqdm\n","import math\n","\n","# Device configuration\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"GPU가 사용 가능합니다.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU를 사용할 수 없습니다.\")"]},{"cell_type":"markdown","metadata":{"id":"qE6813RkYnsf"},"source":["# 데이터 처리"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1687150536960,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"UOJ_i-agRY0o"},"outputs":[],"source":["#datapath = '/content/data'\n","\n","#if not os.path.exists(datapath):\n","##  os.mkdir(datapath)\n","\n","# STL10 data set 다운로드\n","#train_set = datasets.STL10(datapath,split='train', download = True, transform=transforms.ToTensor())\n","#val_set = datasets.STL10(datapath, split='test', download=True, transform=transforms.ToTensor())\n","\n","#print(len(train_set))\n","#print(len(val_set))\n","\n","trainpath = '/content/content/MyDrive/etc/aihub-meat-image/Training/'\n","valpath = '/content/content/MyDrive/etc/aihub-meat-image/Validation/'\n","train_imagepath = os.path.join(trainpath, '[image]cow_seg_')\n","val_imagepath = os.path.join(valpath,'[image]cow_seg_')\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7027,"status":"ok","timestamp":1687150543985,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"Y3qePXGBUVzb"},"outputs":[],"source":["# JSON 파일이 있는 디렉토리 경로\n","train_labelpath = []\n","train_labelpath.append(os.path.join(trainpath, '[label]cow_seg_1'))\n","train_labelpath.append(os.path.join(trainpath, '[label]cow_seg_2'))\n","train_labelpath.append(os.path.join(trainpath, '[label]cow_seg_3'))\n","\n","val_labelpath = []\n","val_labelpath.append(os.path.join(valpath, '[label]cow_seg_1'))\n","val_labelpath.append(os.path.join(valpath, '[label]cow_seg_2'))\n","val_labelpath.append(os.path.join(valpath, '[label]cow_seg_3'))\n","\n","# 라벨 정보를 저장할 딕셔너리\n","jsons = []\n","\n","# JSON 디렉토리 내의 모든 파일에 대해 라벨 정보 추출\n","for path in train_labelpath:\n","  for filename in os.listdir(path):\n","    if filename.endswith(\".json\"):\n","      json_path = os.path.join(path, filename)\n","\n","      # JSON 파일 로드\n","      with open(json_path) as f:\n","        json_data = json.load(f)\n","\n","      # 라벨 정보 추출\n","      jsons.append(json_data)\n","\n","train_labels = []\n","for d in jsons:\n","  label = [d[\"label_info\"][\"image\"][\"file_name\"],\n","           d[\"label_info\"][\"shapes\"][0][\"label\"],\n","           d[\"label_info\"][\"shapes\"][0][\"grade\"],\n","           d[\"label_info\"][\"shapes\"][0][\"gender\"],\n","          ]\n","  train_labels.append(label)\n","\n","# 라벨 정보를 저장할 딕셔너리\n","jsons = []\n","\n","# JSON 디렉토리 내의 모든 파일에 대해 라벨 정보 추출\n","for path in val_labelpath:\n","  for filename in os.listdir(path):\n","    if filename.endswith(\".json\"):\n","      json_path = os.path.join(path, filename)\n","\n","      # JSON 파일 로드\n","      with open(json_path) as f:\n","        json_data = json.load(f)\n","\n","      # 라벨 정보 추출\n","      jsons.append(json_data)\n","\n","val_labels = []\n","for d in jsons:\n","  label = [d[\"label_info\"][\"image\"][\"file_name\"],\n","           d[\"label_info\"][\"shapes\"][0][\"label\"],\n","           d[\"label_info\"][\"shapes\"][0][\"grade\"],\n","           d[\"label_info\"][\"shapes\"][0][\"gender\"],\n","          ]\n","  val_labels.append(label)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1687150543985,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"DvmVfCXpRRxC","outputId":"e9358930-baaa-4dba-f1a3-06534609dd58"},"outputs":[{"name":"stdout","output_type":"stream","text":["                             file_name     label grade  gender\n","0     QC_cow_segmentation_1_003463.jpg    hanwoo     1  female\n","1     QC_cow_segmentation_1_002225.jpg    hanwoo     1  female\n","2     QC_cow_segmentation_1_001673.jpg    hanwoo     1  female\n","3     QC_cow_segmentation_1_001809.jpg    hanwoo     1  female\n","4     QC_cow_segmentation_1_001262.jpg    hanwoo     1   steer\n","...                                ...       ...   ...     ...\n","2995  QC_cow_segmentation_3_011561.jpg  holstein     3   steer\n","2996  QC_cow_segmentation_3_000960.jpg    hanwoo     3  female\n","2997  QC_cow_segmentation_3_013209.jpg  holstein     3   steer\n","2998  QC_cow_segmentation_3_015332.jpg  holstein     3   steer\n","2999  QC_cow_segmentation_3_002319.jpg    hanwoo     3  female\n","\n","[3000 rows x 4 columns]\n","                             file_name     label grade  gender\n","0     QC_cow_segmentation_1_069605.jpg    hanwoo     1   steer\n","1     QC_cow_segmentation_1_069588.jpg    hanwoo     1   steer\n","2     QC_cow_segmentation_1_069603.jpg    hanwoo     1   steer\n","3     QC_cow_segmentation_1_069599.jpg    hanwoo     1   steer\n","4     QC_cow_segmentation_1_069589.jpg    hanwoo     1   steer\n","...                                ...       ...   ...     ...\n","1495  QC_cow_segmentation_3_077330.jpg  holstein     3   steer\n","1496  QC_cow_segmentation_3_077270.jpg  holstein     3   steer\n","1497  QC_cow_segmentation_3_077253.jpg  holstein     3   steer\n","1498  QC_cow_segmentation_3_077218.jpg    hanwoo     3  female\n","1499  QC_cow_segmentation_3_077363.jpg  holstein     3   steer\n","\n","[1500 rows x 4 columns]\n","tensor([[1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.]])\n","                             file_name     label grade  gender  grade_encode\n","0     QC_cow_segmentation_1_003463.jpg    hanwoo     1  female             0\n","1     QC_cow_segmentation_1_002225.jpg    hanwoo     1  female             0\n","2     QC_cow_segmentation_1_001673.jpg    hanwoo     1  female             0\n","3     QC_cow_segmentation_1_001809.jpg    hanwoo     1  female             0\n","4     QC_cow_segmentation_1_001262.jpg    hanwoo     1   steer             0\n","...                                ...       ...   ...     ...           ...\n","2995  QC_cow_segmentation_3_011561.jpg  holstein     3   steer             2\n","2996  QC_cow_segmentation_3_000960.jpg    hanwoo     3  female             2\n","2997  QC_cow_segmentation_3_013209.jpg  holstein     3   steer             2\n","2998  QC_cow_segmentation_3_015332.jpg  holstein     3   steer             2\n","2999  QC_cow_segmentation_3_002319.jpg    hanwoo     3  female             2\n","\n","[3000 rows x 5 columns]\n","                             file_name     label grade  gender  grade_encode\n","0     QC_cow_segmentation_1_069605.jpg    hanwoo     1   steer             0\n","1     QC_cow_segmentation_1_069588.jpg    hanwoo     1   steer             0\n","2     QC_cow_segmentation_1_069603.jpg    hanwoo     1   steer             0\n","3     QC_cow_segmentation_1_069599.jpg    hanwoo     1   steer             0\n","4     QC_cow_segmentation_1_069589.jpg    hanwoo     1   steer             0\n","...                                ...       ...   ...     ...           ...\n","1495  QC_cow_segmentation_3_077330.jpg  holstein     3   steer             2\n","1496  QC_cow_segmentation_3_077270.jpg  holstein     3   steer             2\n","1497  QC_cow_segmentation_3_077253.jpg  holstein     3   steer             2\n","1498  QC_cow_segmentation_3_077218.jpg    hanwoo     3  female             2\n","1499  QC_cow_segmentation_3_077363.jpg  holstein     3   steer             2\n","\n","[1500 rows x 5 columns]\n"]}],"source":["train_label_set = pd.DataFrame(data=train_labels, columns=['file_name','label','grade','gender'])\n","val_label_set = pd.DataFrame(data=val_labels, columns=['file_name','label','grade','gender'])\n","print(train_label_set)\n","print(val_label_set)\n","\n","def grade_encoding(x):\n","  if x == '1':\n","    return 0\n","  elif x == '2':\n","    return 1\n","  elif x== '3':\n","    return 2\n","  return 0\n","\n","one_hot_labels = torch.eye(3)[[0,1,2]]\n","\n","print(one_hot_labels)\n","\n","train_label_set['grade_encode'] = train_label_set['grade'].apply(grade_encoding)\n","val_label_set['grade_encode'] = val_label_set['grade'].apply(grade_encoding)\n","\n","print(train_label_set)\n","print(val_label_set)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1687150543986,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"nrWxqc4Hm8eq"},"outputs":[],"source":["\n","class CustomImageDataset(Dataset):\n","  def __init__(self, labels, img_dir, transform=None, target_transform=None):\n","    self.img_dir = img_dir\n","    self.transform = transform\n","    self.target_transform = target_transform\n","    self.img_labels = labels\n","    #self.train = train\n","    #self.train_len = int(len(labels) * 0.8)\n","    #if train == True:\n","    #  self.img_labels = labels[:self.train_len]\n","    #else:\n","    #  self.img_labels = labels[self.train_len:]\n","\n","  def __len__(self):\n","    return len(self.img_labels)\n","\n","  def __getitem__(self, idx):\n","    img_path = self.img_dir + str(self.img_labels.iloc[idx]['grade'])\n","    img_path = os.path.join(img_path, self.img_labels.iloc[idx, 0])\n","    image = Image.open(img_path)\n","    label = self.img_labels.iloc[idx]['grade_encode']\n","    if self.transform:\n","        image = self.transform(image)\n","    if self.target_transform:\n","        label = self.target_transform(label)\n","    return image, label"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1687150543986,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"3_ZCnqiQSnLi"},"outputs":[],"source":["\n","# 이미지 변형 틀 정의\n","# tensor 형식 + 224로 resize\n","transformation = transforms.Compose([\n","    transforms.Resize([224,224]),\n","    transforms.ToTensor(),\n","    ])\n","\n","# data set에 적용\n","#train_set.transform = transformation\n","#val_set.transform = transformation\n","\n","# data loader 정의\n","#train_dl = DataLoader(train_set, batch_size=32, shuffle=True)\n","#val_dl = DataLoader(val_set, batch_size=64, shuffle=True)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1687150543986,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"-p54C8PLo_fS"},"outputs":[],"source":["train_set = CustomImageDataset(train_label_set, train_imagepath, transform=transformation)\n","val_set = CustomImageDataset(val_label_set, val_imagepath, transform=transformation)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1687150543986,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"WvHgM5GFDdcy","outputId":"60700122-c0e3-4fc2-8ef9-9ab98dfe0db3"},"outputs":[{"data":{"text/plain":["torch.Size([3, 224, 224])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_set[0][0].shape"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":462,"status":"ok","timestamp":1687150544436,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"4mDPOpDWvXuv","outputId":"8341bd69-3159-464f-9920-cc162e8df869"},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]]), 0)\n","(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]]), 0)\n"]}],"source":["print(train_set[0])\n","print(val_set[0])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687150544436,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"cA53jDeZrjcF"},"outputs":[],"source":["train_dl = DataLoader(train_set, batch_size=16, shuffle=True)\n","val_dl = DataLoader(val_set,batch_size=8, shuffle = True)"]},{"cell_type":"markdown","metadata":{"id":"rw3iK4oVZFhA"},"source":["# ViT 구현"]},{"cell_type":"markdown","metadata":{"id":"4ClqNATOoeXa"},"source":["patch embedding"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687150544436,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"3fkRGCALZLwm"},"outputs":[],"source":["# patch embedding 구현\n","# 2D 이미지를 일정 크기의 patch로 나눈다음에 이 patch들을 flat 시킴\n","class PatchEmbedding(nn.Module):\n","  def __init__(self, in_channels=3, patch_size=16,emb_size=768, img_size=224):\n","    super().__init__()\n","    self.patch_size = patch_size\n","\n","    self.projection = nn.Sequential(\n","      Rearrange('b c (h s1) (w s2) -\u003e b (h w) (s1 s2 c)', s1=patch_size, s2=patch_size),\n","      nn.Linear(patch_size * patch_size * in_channels, emb_size)\n","    )\n","\n","    # cls token, position embedding 정의\n","    self.cls_token = nn.Parameter(torch.randn(1,1,emb_size))\n","    self.positions = nn.Parameter(torch.randn((img_size//patch_size)**2 + 1, emb_size))\n","\n","  def forward(self,x):\n","    b = x.shape[0]\n","    x = self.projection(x)\n","    cls_tokens = repeat(self.cls_token, '() n e -\u003e b n e',b=b)\n","    x = torch.cat([cls_tokens, x], dim = 1)\n","    x += self.positions\n","    return x"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1687150544436,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"IxP2ClHdfX3C","outputId":"1971eaf8-9bdd-43bf-8a22-a4a0de3bad88"},"outputs":[{"name":"stdout","output_type":"stream","text":["[batch, 1+num of patches, emb_size] =  torch.Size([16, 197, 768])\n"]}],"source":["# patch embedding test\n","x = torch.randn(16, 3, 224, 224)\n","patch_embedding = PatchEmbedding()\n","patch_output = patch_embedding(x)\n","print('[batch, 1+num of patches, emb_size] = ', patch_output.shape)"]},{"cell_type":"markdown","metadata":{"id":"TZm9s2kAoiL5"},"source":["multi head attention"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1687150544437,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"1Hc--mi3fhKY"},"outputs":[],"source":["# Multi-Head Attention\n","\n","class MultiHeadAttention(nn.Module):\n","  def __init__(self, emb_size=768, num_heads=8, dropout=0):\n","    super().__init__()\n","    self.emb_size = emb_size\n","    self.num_heads = num_heads\n","    self.keys = nn.Linear(emb_size, emb_size)\n","    self.queries = nn.Linear(emb_size, emb_size)\n","    self.values = nn.Linear(emb_size, emb_size)\n","    self.att_drop = nn.Dropout(dropout)\n","    self.projection = nn.Linear(emb_size, emb_size)\n","\n","  def forward(self, x, mask=None):\n","    # key , query, value로 나누기\n","    # b, 197, 728 -\u003e b, 8, 197, 91\n","    queries = rearrange(self.queries(x), 'b n (h d) -\u003e b h n d', h=self.num_heads)\n","    keys = rearrange(self.keys(x), 'b n (h d) -\u003e b h n d', h=self.num_heads)\n","    values = rearrange(self.values(x), 'b n (h d) -\u003e b h n d', h=self.num_heads)\n","\n","    # matrix multiplication between queries and keys\n","    energy = torch.einsum('bhqd, bhkd -\u003e bhqk', queries, keys) # batch, num_head, query_len, key_len\n","\n","    if mask is not None:\n","      fill_value = torch.finfo(torch.float32).min\n","      energy.mask_fill(-mask,fill_value)\n","\n","    scaling = self.emb_size ** (1/2)\n","    att = F.softmax(energy, dim=-1) / scaling\n","    att = self.att_drop(att)\n","\n","    out = torch.einsum('bhal, bhlv -\u003e bhav', att, values)\n","    out = rearrange(out, 'b h n d -\u003e b n (h d)')\n","    out = self.projection(out)\n","    return out"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1687150544736,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"c8qbIxUblnK9","outputId":"7b18bc7a-a5cf-4546-c25c-dbc5159fb71f"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 197, 768])\n"]}],"source":["# MultiHeadAttention test\n","MHA = MultiHeadAttention()\n","MHA_output = MHA(patch_output)\n","print(MHA_output.shape)"]},{"cell_type":"markdown","metadata":{"id":"eLd6Dhh5onZp"},"source":["residual"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687150544737,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"QkACJGgTmAp3"},"outputs":[],"source":["# Residual\n","\n","class ResidualAdd(nn.Module):\n","  def __init__(self, fn):\n","    super().__init__()\n","    self.fn = fn\n","\n","  def forward(self, x, **kwargs):\n","    res = x\n","    x = self.fn(x, **kwargs)\n","    x += res\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"QrnDGRTloysn"},"source":["Feed Forward Block"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1687150544737,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"nBlUOn3hopID"},"outputs":[],"source":["#Feed Foward Block\n","class FeedForwardBlock(nn.Sequential):\n","  def __init__(self, emb_size, expansion=4, drop_p=0):\n","    super().__init__(\n","        nn.Linear(emb_size,expansion*emb_size),\n","        nn.GELU(),\n","        nn.Dropout(drop_p),\n","        nn.Linear(expansion * emb_size, emb_size),\n","    )\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1687150544737,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"zjVuS_pzpgBj","outputId":"ec88a3fe-e752-4e35-f8b6-9d25fc1bff0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 1, 128])\n"]}],"source":["# test\n","x = torch.randn(16,1,128)\n","model = FeedForwardBlock(128)\n","output = model(x)\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{"id":"eklz3m2ipzCu"},"source":["Encoder"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":305,"status":"ok","timestamp":1687150545040,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"Ykj1IQKupykX"},"outputs":[],"source":["class TransformerEncoderBlock(nn.Sequential):\n","  def __init__(self, emb_size=768, drop_p=0., forward_expansion=4, forward_drop_p=0., **kwargs):\n","    super().__init__(\n","        ResidualAdd(nn.Sequential(\n","            nn.LayerNorm(emb_size),\n","            MultiHeadAttention(emb_size, **kwargs),\n","            nn.Dropout(drop_p)\n","        )),\n","        ResidualAdd(nn.Sequential(\n","            nn.LayerNorm(emb_size),\n","            FeedForwardBlock(emb_size, **kwargs),\n","            nn.Dropout(drop_p)\n","        ))\n","    )"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1339,"status":"ok","timestamp":1687150546377,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"dqtssJGW6OnP","outputId":"0efcb5eb-e182-4450-9eb5-510d90db378a"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 197, 768])\n"]}],"source":["# TransformerEncoderBlock test\n","model = TransformerEncoderBlock()\n","output = model(patch_output)\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{"id":"yGouanE76yXh"},"source":["Transformer"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1687150546377,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"LX5_tyvT64fL"},"outputs":[],"source":["class TransformerEncoder(nn.Sequential):\n","  def __init__(self, depth=12, **kwargs):\n","    super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9906,"status":"ok","timestamp":1687150556281,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"obAqFl_47UGD","outputId":"048da059-e7a8-4a25-a87e-0a77b7243f6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 197, 768])\n"]}],"source":["#TransformerEncoder test\n","model = TransformerEncoder()\n","output = model(patch_output)\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{"id":"h9LsvJDM7qKO"},"source":["Classification Head"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1687150556281,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"sb89uNWE7aCC"},"outputs":[],"source":["#Classification Head\n","class ClassificationHead(nn.Sequential):\n","  def __init__(self, emb_size=768, n_classes=10):\n","    super().__init__(\n","        Reduce('b n e -\u003e b e', reduction='mean'),\n","        nn.LayerNorm(emb_size),\n","        nn.Linear(emb_size, n_classes)\n","    )"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1687150556282,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"C-iSDVRf8MDk","outputId":"9e558b31-fde6-4078-82d1-3bee665a6776"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 10])\n","tensor([[-0.1756, -0.3962, -0.7319,  0.9893,  0.5073, -0.8378, -0.0500, -0.1542,\n","         -0.1830,  0.1590],\n","        [-0.3236, -0.1310,  0.0840, -0.0656, -0.5988, -0.1810,  0.5672,  0.1301,\n","          0.9058, -0.3975],\n","        [-0.2422,  0.5345, -1.0108,  0.5492, -0.5773,  0.6671, -0.0065, -0.1982,\n","         -0.9336, -0.2522],\n","        [ 0.0274, -0.9949,  0.6455,  0.5396,  0.2553,  0.3228, -0.4100,  0.3233,\n","          0.1157, -0.1160],\n","        [ 0.6084,  0.8529,  0.1225,  0.6400,  1.0559,  0.1767, -0.1677, -1.0577,\n","         -0.3706,  0.5752],\n","        [ 0.7302, -0.0735,  0.1970, -0.6718, -0.2570,  0.9854, -0.3303,  0.4793,\n","         -0.1289,  0.6237],\n","        [-0.4581,  0.4324,  0.9388, -0.2118, -0.0528,  0.7740,  0.2034, -0.6981,\n","         -0.3094, -0.6294],\n","        [-0.7056,  0.3142, -0.6580,  0.8068,  0.3903, -0.0375,  0.6319, -0.3740,\n","         -0.3815,  0.1366],\n","        [ 0.5644, -0.2214,  0.2263, -0.0865,  0.2352, -0.5273, -0.9620,  0.1701,\n","         -0.1206,  0.7289],\n","        [-0.0204, -0.4384,  0.5689,  0.3118, -0.0733,  0.9277,  0.0793,  0.4230,\n","          0.8684,  0.4581],\n","        [ 0.2039,  0.9203, -0.1117,  0.0186, -0.2950, -0.4231,  0.0834, -0.7380,\n","          0.4828, -0.2270],\n","        [ 0.1817, -0.2404, -1.4447,  0.2133, -0.1481,  0.2120, -0.1696, -0.8456,\n","         -0.1797,  0.4019],\n","        [-0.3198, -0.8841,  0.4214, -1.2392, -0.2516,  0.4745,  0.1960,  1.1733,\n","         -0.3895, -0.1619],\n","        [ 0.0732, -0.0210, -0.5091,  0.4712, -0.2419,  0.2207,  0.1851, -0.5904,\n","          0.1285, -0.8329],\n","        [ 0.4559, -0.4275,  0.5142, -0.3896, -0.1829,  0.1725, -0.8644,  0.6085,\n","         -0.1644, -0.0387],\n","        [ 0.3475,  0.6283, -0.2749,  0.7762,  0.6008, -0.5335, -0.4411, -0.4141,\n","         -0.5365,  0.3783]], grad_fn=\u003cAddmmBackward0\u003e)\n"]}],"source":["# Classification Head test\n","x = torch.randn(16, 1, 768)\n","model = ClassificationHead()\n","output = model(x)\n","print(output.shape)\n","print(output)"]},{"cell_type":"markdown","metadata":{"id":"2aAobWJ58XXA"},"source":["ViT"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1687150556282,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"ggVGFlF_8YrJ"},"outputs":[],"source":["# ViT\n","class ViT(nn.Sequential):\n","  def __init__(self, in_channels=3, patch_size=16,emb_size=768,img_size=224,depth=12,n_classes=10, **kwargs):\n","    super().__init__(\n","        PatchEmbedding(in_channels, patch_size, emb_size, img_size),\n","        TransformerEncoder(depth, emb_size=emb_size, **kwargs),\n","        ClassificationHead(emb_size, n_classes)\n","    )\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3732,"status":"ok","timestamp":1687150560002,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"x_wiZJnk9Cto","outputId":"29e65446-56aa-40f2-f06b-740cd65009d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3])\n","tensor([[ 1.2018, -0.1067,  0.0368],\n","        [ 1.3140,  0.0887, -0.2325],\n","        [ 1.1362, -0.2226, -0.0786],\n","        [ 1.1904, -0.1666, -0.3068],\n","        [ 1.2641, -0.0335, -0.1170],\n","        [ 1.2406, -0.2646, -0.0852],\n","        [ 1.3557, -0.2209, -0.1937],\n","        [ 1.1473, -0.1054, -0.0439],\n","        [ 1.0723, -0.2278,  0.1508],\n","        [ 1.2304, -0.0989, -0.0146],\n","        [ 1.3120, -0.1242, -0.1207],\n","        [ 1.2713, -0.1714, -0.1558],\n","        [ 1.2936, -0.0825, -0.0918],\n","        [ 1.2397, -0.1886, -0.2195],\n","        [ 0.9669, -0.0925,  0.1166],\n","        [ 1.2676, -0.2016, -0.2853]], device='cuda:0',\n","       grad_fn=\u003cAddmmBackward0\u003e)\n"]}],"source":["# ViT test\n","hyperparameter = {\n","    'patch_size': 16,\n","    'emb_size': 768,\n","    'img_size':224,\n","    'depth':12,\n","    'n_classes':1,\n","}\n","x = torch.randn(16,3,224,224).to(device)\n","model = ViT(n_classes=3).to(device)\n","output = model(x)\n","print(output.shape)\n","print(output)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2076,"status":"ok","timestamp":1687150562076,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"p58nEQY1IshH","outputId":"6897b2c4-49ac-4e2f-88d3-05b88ff6b613"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","         Rearrange-1             [-1, 196, 768]               0\n","            Linear-2             [-1, 196, 768]         590,592\n","    PatchEmbedding-3             [-1, 197, 768]               0\n","         LayerNorm-4             [-1, 197, 768]           1,536\n","            Linear-5             [-1, 197, 768]         590,592\n","            Linear-6             [-1, 197, 768]         590,592\n","            Linear-7             [-1, 197, 768]         590,592\n","           Dropout-8          [-1, 8, 197, 197]               0\n","            Linear-9             [-1, 197, 768]         590,592\n","MultiHeadAttention-10             [-1, 197, 768]               0\n","          Dropout-11             [-1, 197, 768]               0\n","      ResidualAdd-12             [-1, 197, 768]               0\n","        LayerNorm-13             [-1, 197, 768]           1,536\n","           Linear-14            [-1, 197, 3072]       2,362,368\n","             GELU-15            [-1, 197, 3072]               0\n","          Dropout-16            [-1, 197, 3072]               0\n","           Linear-17             [-1, 197, 768]       2,360,064\n","          Dropout-18             [-1, 197, 768]               0\n","      ResidualAdd-19             [-1, 197, 768]               0\n","        LayerNorm-20             [-1, 197, 768]           1,536\n","           Linear-21             [-1, 197, 768]         590,592\n","           Linear-22             [-1, 197, 768]         590,592\n","           Linear-23             [-1, 197, 768]         590,592\n","          Dropout-24          [-1, 8, 197, 197]               0\n","           Linear-25             [-1, 197, 768]         590,592\n","MultiHeadAttention-26             [-1, 197, 768]               0\n","          Dropout-27             [-1, 197, 768]               0\n","      ResidualAdd-28             [-1, 197, 768]               0\n","        LayerNorm-29             [-1, 197, 768]           1,536\n","           Linear-30            [-1, 197, 3072]       2,362,368\n","             GELU-31            [-1, 197, 3072]               0\n","          Dropout-32            [-1, 197, 3072]               0\n","           Linear-33             [-1, 197, 768]       2,360,064\n","          Dropout-34             [-1, 197, 768]               0\n","      ResidualAdd-35             [-1, 197, 768]               0\n","        LayerNorm-36             [-1, 197, 768]           1,536\n","           Linear-37             [-1, 197, 768]         590,592\n","           Linear-38             [-1, 197, 768]         590,592\n","           Linear-39             [-1, 197, 768]         590,592\n","          Dropout-40          [-1, 8, 197, 197]               0\n","           Linear-41             [-1, 197, 768]         590,592\n","MultiHeadAttention-42             [-1, 197, 768]               0\n","          Dropout-43             [-1, 197, 768]               0\n","      ResidualAdd-44             [-1, 197, 768]               0\n","        LayerNorm-45             [-1, 197, 768]           1,536\n","           Linear-46            [-1, 197, 3072]       2,362,368\n","             GELU-47            [-1, 197, 3072]               0\n","          Dropout-48            [-1, 197, 3072]               0\n","           Linear-49             [-1, 197, 768]       2,360,064\n","          Dropout-50             [-1, 197, 768]               0\n","      ResidualAdd-51             [-1, 197, 768]               0\n","        LayerNorm-52             [-1, 197, 768]           1,536\n","           Linear-53             [-1, 197, 768]         590,592\n","           Linear-54             [-1, 197, 768]         590,592\n","           Linear-55             [-1, 197, 768]         590,592\n","          Dropout-56          [-1, 8, 197, 197]               0\n","           Linear-57             [-1, 197, 768]         590,592\n","MultiHeadAttention-58             [-1, 197, 768]               0\n","          Dropout-59             [-1, 197, 768]               0\n","      ResidualAdd-60             [-1, 197, 768]               0\n","        LayerNorm-61             [-1, 197, 768]           1,536\n","           Linear-62            [-1, 197, 3072]       2,362,368\n","             GELU-63            [-1, 197, 3072]               0\n","          Dropout-64            [-1, 197, 3072]               0\n","           Linear-65             [-1, 197, 768]       2,360,064\n","          Dropout-66             [-1, 197, 768]               0\n","      ResidualAdd-67             [-1, 197, 768]               0\n","        LayerNorm-68             [-1, 197, 768]           1,536\n","           Linear-69             [-1, 197, 768]         590,592\n","           Linear-70             [-1, 197, 768]         590,592\n","           Linear-71             [-1, 197, 768]         590,592\n","          Dropout-72          [-1, 8, 197, 197]               0\n","           Linear-73             [-1, 197, 768]         590,592\n","MultiHeadAttention-74             [-1, 197, 768]               0\n","          Dropout-75             [-1, 197, 768]               0\n","      ResidualAdd-76             [-1, 197, 768]               0\n","        LayerNorm-77             [-1, 197, 768]           1,536\n","           Linear-78            [-1, 197, 3072]       2,362,368\n","             GELU-79            [-1, 197, 3072]               0\n","          Dropout-80            [-1, 197, 3072]               0\n","           Linear-81             [-1, 197, 768]       2,360,064\n","          Dropout-82             [-1, 197, 768]               0\n","      ResidualAdd-83             [-1, 197, 768]               0\n","        LayerNorm-84             [-1, 197, 768]           1,536\n","           Linear-85             [-1, 197, 768]         590,592\n","           Linear-86             [-1, 197, 768]         590,592\n","           Linear-87             [-1, 197, 768]         590,592\n","          Dropout-88          [-1, 8, 197, 197]               0\n","           Linear-89             [-1, 197, 768]         590,592\n","MultiHeadAttention-90             [-1, 197, 768]               0\n","          Dropout-91             [-1, 197, 768]               0\n","      ResidualAdd-92             [-1, 197, 768]               0\n","        LayerNorm-93             [-1, 197, 768]           1,536\n","           Linear-94            [-1, 197, 3072]       2,362,368\n","             GELU-95            [-1, 197, 3072]               0\n","          Dropout-96            [-1, 197, 3072]               0\n","           Linear-97             [-1, 197, 768]       2,360,064\n","          Dropout-98             [-1, 197, 768]               0\n","      ResidualAdd-99             [-1, 197, 768]               0\n","       LayerNorm-100             [-1, 197, 768]           1,536\n","          Linear-101             [-1, 197, 768]         590,592\n","          Linear-102             [-1, 197, 768]         590,592\n","          Linear-103             [-1, 197, 768]         590,592\n","         Dropout-104          [-1, 8, 197, 197]               0\n","          Linear-105             [-1, 197, 768]         590,592\n","MultiHeadAttention-106             [-1, 197, 768]               0\n","         Dropout-107             [-1, 197, 768]               0\n","     ResidualAdd-108             [-1, 197, 768]               0\n","       LayerNorm-109             [-1, 197, 768]           1,536\n","          Linear-110            [-1, 197, 3072]       2,362,368\n","            GELU-111            [-1, 197, 3072]               0\n","         Dropout-112            [-1, 197, 3072]               0\n","          Linear-113             [-1, 197, 768]       2,360,064\n","         Dropout-114             [-1, 197, 768]               0\n","     ResidualAdd-115             [-1, 197, 768]               0\n","       LayerNorm-116             [-1, 197, 768]           1,536\n","          Linear-117             [-1, 197, 768]         590,592\n","          Linear-118             [-1, 197, 768]         590,592\n","          Linear-119             [-1, 197, 768]         590,592\n","         Dropout-120          [-1, 8, 197, 197]               0\n","          Linear-121             [-1, 197, 768]         590,592\n","MultiHeadAttention-122             [-1, 197, 768]               0\n","         Dropout-123             [-1, 197, 768]               0\n","     ResidualAdd-124             [-1, 197, 768]               0\n","       LayerNorm-125             [-1, 197, 768]           1,536\n","          Linear-126            [-1, 197, 3072]       2,362,368\n","            GELU-127            [-1, 197, 3072]               0\n","         Dropout-128            [-1, 197, 3072]               0\n","          Linear-129             [-1, 197, 768]       2,360,064\n","         Dropout-130             [-1, 197, 768]               0\n","     ResidualAdd-131             [-1, 197, 768]               0\n","       LayerNorm-132             [-1, 197, 768]           1,536\n","          Linear-133             [-1, 197, 768]         590,592\n","          Linear-134             [-1, 197, 768]         590,592\n","          Linear-135             [-1, 197, 768]         590,592\n","         Dropout-136          [-1, 8, 197, 197]               0\n","          Linear-137             [-1, 197, 768]         590,592\n","MultiHeadAttention-138             [-1, 197, 768]               0\n","         Dropout-139             [-1, 197, 768]               0\n","     ResidualAdd-140             [-1, 197, 768]               0\n","       LayerNorm-141             [-1, 197, 768]           1,536\n","          Linear-142            [-1, 197, 3072]       2,362,368\n","            GELU-143            [-1, 197, 3072]               0\n","         Dropout-144            [-1, 197, 3072]               0\n","          Linear-145             [-1, 197, 768]       2,360,064\n","         Dropout-146             [-1, 197, 768]               0\n","     ResidualAdd-147             [-1, 197, 768]               0\n","       LayerNorm-148             [-1, 197, 768]           1,536\n","          Linear-149             [-1, 197, 768]         590,592\n","          Linear-150             [-1, 197, 768]         590,592\n","          Linear-151             [-1, 197, 768]         590,592\n","         Dropout-152          [-1, 8, 197, 197]               0\n","          Linear-153             [-1, 197, 768]         590,592\n","MultiHeadAttention-154             [-1, 197, 768]               0\n","         Dropout-155             [-1, 197, 768]               0\n","     ResidualAdd-156             [-1, 197, 768]               0\n","       LayerNorm-157             [-1, 197, 768]           1,536\n","          Linear-158            [-1, 197, 3072]       2,362,368\n","            GELU-159            [-1, 197, 3072]               0\n","         Dropout-160            [-1, 197, 3072]               0\n","          Linear-161             [-1, 197, 768]       2,360,064\n","         Dropout-162             [-1, 197, 768]               0\n","     ResidualAdd-163             [-1, 197, 768]               0\n","       LayerNorm-164             [-1, 197, 768]           1,536\n","          Linear-165             [-1, 197, 768]         590,592\n","          Linear-166             [-1, 197, 768]         590,592\n","          Linear-167             [-1, 197, 768]         590,592\n","         Dropout-168          [-1, 8, 197, 197]               0\n","          Linear-169             [-1, 197, 768]         590,592\n","MultiHeadAttention-170             [-1, 197, 768]               0\n","         Dropout-171             [-1, 197, 768]               0\n","     ResidualAdd-172             [-1, 197, 768]               0\n","       LayerNorm-173             [-1, 197, 768]           1,536\n","          Linear-174            [-1, 197, 3072]       2,362,368\n","            GELU-175            [-1, 197, 3072]               0\n","         Dropout-176            [-1, 197, 3072]               0\n","          Linear-177             [-1, 197, 768]       2,360,064\n","         Dropout-178             [-1, 197, 768]               0\n","     ResidualAdd-179             [-1, 197, 768]               0\n","       LayerNorm-180             [-1, 197, 768]           1,536\n","          Linear-181             [-1, 197, 768]         590,592\n","          Linear-182             [-1, 197, 768]         590,592\n","          Linear-183             [-1, 197, 768]         590,592\n","         Dropout-184          [-1, 8, 197, 197]               0\n","          Linear-185             [-1, 197, 768]         590,592\n","MultiHeadAttention-186             [-1, 197, 768]               0\n","         Dropout-187             [-1, 197, 768]               0\n","     ResidualAdd-188             [-1, 197, 768]               0\n","       LayerNorm-189             [-1, 197, 768]           1,536\n","          Linear-190            [-1, 197, 3072]       2,362,368\n","            GELU-191            [-1, 197, 3072]               0\n","         Dropout-192            [-1, 197, 3072]               0\n","          Linear-193             [-1, 197, 768]       2,360,064\n","         Dropout-194             [-1, 197, 768]               0\n","     ResidualAdd-195             [-1, 197, 768]               0\n","          Reduce-196                  [-1, 768]               0\n","       LayerNorm-197                  [-1, 768]           1,536\n","          Linear-198                   [-1, 10]           7,690\n","================================================================\n","Total params: 85,654,282\n","Trainable params: 85,654,282\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 364.33\n","Params size (MB): 326.75\n","Estimated Total Size (MB): 691.64\n","----------------------------------------------------------------\n"]}],"source":["summary(ViT(), (3, 224, 224),device='cpu')"]},{"cell_type":"markdown","metadata":{"id":"epML-X7U9pzE"},"source":["Training"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687150562076,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"GmaQ_qva9pVs"},"outputs":[],"source":["loss_func = nn.CrossEntropyLoss(reduction='sum')\n","opt = optim.Adam(model.parameters(), lr=0.01)\n","\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687150562076,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"28P3ur_e-qxb"},"outputs":[],"source":["# get current lr\n","def get_lr(opt):\n","    for param_group in opt.param_groups:\n","        return param_group['lr']"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1687150846623,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"GCMM-6Hm-tID"},"outputs":[],"source":["# calculate the metric per mini-batch\n","def metric_batch(output, target):\n","    pred = output.argmax(1, keepdim=True)\n","    corrects = pred.eq(target.view_as(pred)).sum().item()\n","    return corrects\n","\n","# calculate the loss per mini-batch\n","def loss_batch(loss_func, output, target, opt=None):\n","    loss_b = loss_func(output, target)\n","    metric_b = metric_batch(output, target)\n","\n","    if opt is not None:\n","        opt.zero_grad()\n","        loss_b.backward()\n","        opt.step()\n","\n","    return loss_b.item(), metric_b\n","\n","# calculate the loss per epochs\n","def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n","    running_loss = 0.0\n","    running_metric = 0.0\n","    len_data = len(dataset_dl.dataset)\n","\n","    for xb, yb in dataset_dl:\n","        xb = xb.to(device)\n","        yb = yb.to(device)\n","        output = model(xb)\n","        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n","\n","        running_loss += loss_b\n","\n","        if metric_b is not None:\n","            running_metric += metric_b\n","\n","        if sanity_check is True:\n","            break\n","\n","    loss = running_loss / len_data\n","    metric = running_metric / len_data\n","    return loss, metric"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":297,"status":"ok","timestamp":1687150849379,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"m6pB-wej_JJT"},"outputs":[],"source":["# function to start training\n","def train_val(model, params):\n","    num_epochs=params['num_epochs']\n","    loss_func=params['loss_func']\n","    opt=params['optimizer']\n","    train_dl=params['train_dl']\n","    val_dl=params['val_dl']\n","    sanity_check=params['sanity_check']\n","    lr_scheduler=params['lr_scheduler']\n","    path2weights=params['path2weights']\n","\n","    loss_history = {'train': [], 'val': []}\n","    metric_history = {'train': [], 'val': []}\n","\n","    best_loss = float('inf')\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    start_time = time.time()\n","\n","    for epoch in range(num_epochs):\n","        current_lr = get_lr(opt)\n","        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n","\n","        model.train()\n","        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n","        loss_history['train'].append(train_loss)\n","        metric_history['train'].append(train_metric)\n","\n","        model.eval()\n","        with torch.no_grad():\n","            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n","        loss_history['val'].append(val_loss)\n","        metric_history['val'].append(val_metric)\n","\n","        if val_loss \u003c best_loss:\n","            best_loss = val_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            torch.save(model.state_dict(), path2weights)\n","            print('Copied best model weights!')\n","\n","        lr_scheduler.step(val_loss)\n","        if current_lr != get_lr(opt):\n","            print('Loading best model weights!')\n","            model.load_state_dict(best_model_wts)\n","\n","        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n","        print('-'*10)\n","\n","    model.load_state_dict(best_model_wts)\n","    return model, loss_history, metric_history"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1687151686798,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"eAUUlrz5_se2"},"outputs":[],"source":["# define the training parameters\n","params_train = {\n","    'num_epochs':20,\n","    'optimizer':opt,\n","    'loss_func':loss_func,\n","    'train_dl':train_dl,\n","    'val_dl':val_dl,\n","    'sanity_check':False,\n","    'lr_scheduler':lr_scheduler,\n","    'path2weights':'./models/weights.pt',\n","}\n","\n","# check the directory to save weights.pt\n","def createFolder(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSError:\n","        print('Error')\n","createFolder('./models')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Fxlx6oL8AGvB"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/19, current lr= 0.01\n","Copied best model weights!\n","train loss: 1.101988, val loss: 1.098820, accuracy: 33.33, time: 4.6195 min\n","----------\n","Epoch 1/19, current lr= 0.01\n","Copied best model weights!\n","train loss: 1.101845, val loss: 1.098670, accuracy: 33.33, time: 9.2295 min\n","----------\n","Epoch 2/19, current lr= 0.01\n","train loss: 1.101305, val loss: 1.099607, accuracy: 33.33, time: 13.8234 min\n","----------\n","Epoch 3/19, current lr= 0.01\n","train loss: 1.102555, val loss: 1.098858, accuracy: 33.33, time: 18.4267 min\n","----------\n","Epoch 4/19, current lr= 0.01\n","train loss: 1.100264, val loss: 1.099193, accuracy: 33.33, time: 23.0078 min\n","----------\n","Epoch 5/19, current lr= 0.01\n","train loss: 1.101719, val loss: 1.099201, accuracy: 33.33, time: 27.6068 min\n","----------\n","Epoch 6/19, current lr= 0.01\n","train loss: 1.101269, val loss: 1.101156, accuracy: 33.33, time: 32.2022 min\n","----------\n","Epoch 7/19, current lr= 0.01\n","train loss: 1.101554, val loss: 1.102144, accuracy: 33.33, time: 36.7947 min\n","----------\n","Epoch 8/19, current lr= 0.01\n","train loss: 1.103764, val loss: 1.100955, accuracy: 33.33, time: 41.4225 min\n","----------\n","Epoch 9/19, current lr= 0.01\n","train loss: 1.101261, val loss: 1.098750, accuracy: 33.33, time: 46.0440 min\n","----------\n","Epoch 10/19, current lr= 0.01\n","train loss: 1.107070, val loss: 1.101095, accuracy: 33.33, time: 50.7135 min\n","----------\n","Epoch 11/19, current lr= 0.01\n","train loss: 1.104905, val loss: 1.099192, accuracy: 33.33, time: 55.3533 min\n","----------\n","Epoch 12/19, current lr= 0.01\n","Loading best model weights!\n","train loss: 1.103875, val loss: 1.104448, accuracy: 33.33, time: 59.9616 min\n","----------\n","Epoch 13/19, current lr= 0.001\n","Copied best model weights!\n","train loss: 1.098962, val loss: 1.098621, accuracy: 33.33, time: 64.5927 min\n","----------\n","Epoch 14/19, current lr= 0.001\n","Copied best model weights!\n","train loss: 1.098808, val loss: 1.098613, accuracy: 33.33, time: 69.2500 min\n","----------\n","Epoch 15/19, current lr= 0.001\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-40-efe884e75623\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 2\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-36-72cdf47736dc\u003e\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 24\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanity_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmetric_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-35-e94b366eaa23\u003e\u001b[0m in \u001b[0;36mloss_epoch\u001b[0;34m(model, loss_func, dataset_dl, sanity_check, opt)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m\u003clistcomp\u003e\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-7-1258b1dec796\u003e\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grade'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 20\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grade_encode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Start training\n","model, loss_hist, metric_hist = train_val(model, params_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1687150820422,"user":{"displayName":"소프트웨어학과/이진혁","userId":"00278177220097568307"},"user_tz":-540},"id":"V4AEYKVX4Xes"},"outputs":[],"source":["num_epochs = params_train['num_epochs']\n","\n","# Plot train-val loss\n","plt.title('Train-Val Loss')\n","plt.plot(range(1, num_epochs+1), loss_hist['train'], label='train')\n","plt.plot(range(1, num_epochs+1), loss_hist['val'], label='val')\n","plt.ylabel('Loss')\n","plt.xlabel('Training Epochs')\n","plt.legend()\n","plt.show()\n","\n","# plot train-val accuracy\n","plt.title('Train-Val Accuracy')\n","plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')\n","plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Training Epochs')\n","plt.legend()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNuuq5FojJwjR4EsoEcrGzY","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}